{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b658081e"
      },
      "source": [
        "pip install xlsxwriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install geopandas"
      ],
      "metadata": {
        "id": "F5jEmUo1Z4aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install contextily"
      ],
      "metadata": {
        "id": "O2Fds0T1Z9ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pygbif"
      ],
      "metadata": {
        "id": "vV0wCwnYevEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xarray netCDF4 matplotlib"
      ],
      "metadata": {
        "id": "fTNfOC6WNNjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xarray netCDF4 matplotlib"
      ],
      "metadata": {
        "id": "rh0N1A6RTUeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9rwECzWMaJyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ADDING FEATURE - SPECIES TYPE - FINAL PEICE OF CODE\n",
        "from pygbif import species\n",
        "\n",
        "reptile_genera = [\n",
        "    \"Lophognathus\", \"Liolaemus\", \"Saproscincus\", \"Agama\", \"Plestiodon\",\n",
        "    \"Philothamnus\", \"Sanzinia\", \"Ctenophorus\", \"Morethia\", \"Trimeresurus\",\n",
        "    \"Atractus\", \"Phoenicolacerta\", \"Causus\", \"Contia\", \"Elgaria\",\n",
        "    \"Chalcides\", \"Liodytes\", \"Chironius\", \"Tropidurus\", \"Dipsas\",\n",
        "    \"Gallotia\", \"Pachydactylus\", \"Vipera\", \"Anguis\", \"Oligodon\",\n",
        "    \"Pedioplanis\", \"Sceloporus\", \"Urosaurus\", \"Phrynosoma\", \"Bronchocela\",\n",
        "    \"Alligator\", \"Gambelia\", \"Cacophis\", \"Boa\", \"Trioceros\",\n",
        "    \"Pseudechis\", \"Pseudaspis\", \"Helicops\", \"Ctenotus\", \"Trachylepis\",\n",
        "    \"Tiliqua\", \"Lycodon\", \"Malayemys\", \"Elaphe\", \"Crotaphytus\",\n",
        "    \"Pogona\", \"Nerodia\", \"Nebulifera\", \"Python\", \"Lacerta\",\n",
        "    \"Eutropis\", \"Lampropeltis\", \"Masticophis\", \"Afrogecko\", \"Naja\",\n",
        "    \"Takydromus\", \"Amphisbaena\", \"Natrix\", \"Dispholidus\", \"Holcosus\",\n",
        "    \"Furcifer\", \"Lycophidion\", \"Cyrtodactylus\", \"Chamaeleo\", \"Lamprophis\",\n",
        "    \"Coelognathus\", \"Gambelia\", \"Lycodonomorphus\"\n",
        "]\n",
        "reptile_genus_to_group = {genus: \"Reptile\" for genus in reptile_genera}\n",
        "\n",
        "order_to_group = {\n",
        "    'Squamata': 'Reptile', 'Testudines': 'Reptile', 'Crocodylia': 'Reptile',\n",
        "    'Anura': 'Amphibian', 'Caudata': 'Amphibian',\n",
        "    'Passeriformes': 'Bird', 'Accipitriformes': 'Bird', 'Columbiformes': 'Bird',\n",
        "    'Psittaciformes': 'Bird', 'Strigiformes': 'Bird', 'Falconiformes': 'Bird',\n",
        "    'Carnivora': 'Mammal', 'Primates': 'Mammal', 'Rodentia': 'Mammal', 'Chiroptera': 'Mammal'\n",
        "}\n",
        "\n",
        "class_to_group = {\n",
        "    'Amphibia': 'Amphibian',\n",
        "    'Aves': 'Bird',\n",
        "    'Mammalia': 'Mammal'\n",
        "}\n",
        "\n",
        "def classify_species(scientific_name):\n",
        "    try:\n",
        "        genus = scientific_name.split()[0]\n",
        "\n",
        "        if genus in reptile_genus_to_group:\n",
        "            return \"Reptile\"\n",
        "\n",
        "        res = species.name_backbone(scientific_name, strict=False)\n",
        "        cls = res.get('class')\n",
        "        order = res.get('order')\n",
        "\n",
        "        if cls in class_to_group:\n",
        "            return class_to_group[cls]\n",
        "        if order in order_to_group:\n",
        "            return order_to_group[order]\n",
        "\n",
        "        res_genus = species.name_backbone(genus, strict=False)\n",
        "        cls_genus = res_genus.get('class')\n",
        "        order_genus = res_genus.get('order')\n",
        "        if cls_genus in class_to_group:\n",
        "            return class_to_group[cls_genus]\n",
        "        if order_genus in order_to_group:\n",
        "            return order_to_group[order_genus]\n",
        "\n",
        "        return \"Unknown\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"Unknown\""
      ],
      "metadata": {
        "id": "Jm8m-DBNel8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_excel(\"./dataprep/species_train.xlsx\", sheet_name='taxon_names')\n",
        "df1.rename(columns={0: 'taxon_names'}, inplace=True)\n",
        "df1['taxon_names'] = df1['taxon_names'].astype(str).str.strip()\n",
        "df1['Group'] = df1['taxon_names'].apply(classify_species)\n",
        "with pd.ExcelWriter(\"./dataprep/species_train.xlsx\", engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
        "    df1.to_excel(writer, sheet_name='taxon_names', index=False)"
      ],
      "metadata": {
        "id": "s8BVyt4sg3Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1.head())"
      ],
      "metadata": {
        "id": "3iYzgLkvjANZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ADDING FEATURE - SPECIES TYPE - FINAL PEICE OF CODE\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "excel_file = \"./dataprep/species_train.xlsx\"\n",
        "\n",
        "\n",
        "df_locs = pd.read_excel(excel_file, sheet_name='train_locs')\n",
        "df_ids = pd.read_excel(excel_file, sheet_name='train_ids')\n",
        "df_taxon_ids = pd.read_excel(excel_file, sheet_name='taxon_ids')\n",
        "df_taxon_names = pd.read_excel(excel_file, sheet_name='taxon_names')\n",
        "df_locs = df_locs.rename(columns={0:'latitude', 1:'longitude'})\n",
        "\n",
        "df_taxon_full = pd.concat([df_taxon_ids.reset_index(drop=True), df_taxon_names.reset_index(drop=True)], axis=1)\n",
        "df_merged = pd.concat([df_locs[['latitude','longitude']], df_ids[['train_ids']]], axis=1)\n",
        "df_merged = df_merged[df_merged['train_ids'].isin(df_taxon_full['taxon_ids'])]\n",
        "df_final = df_merged.merge(\n",
        "    df_taxon_full,\n",
        "    left_on='train_ids',\n",
        "    right_on='taxon_ids',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "df_final = df_final.rename(columns={'taxon_names':'taxon_name', 'Group':'type'})\\\n",
        "                   [['latitude', 'longitude', 'train_ids', 'taxon_name', 'type']]\n",
        "\n",
        "print(df_final.head())"
      ],
      "metadata": {
        "id": "IqgQcWtlnx3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with pd.ExcelWriter(excel_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
        "    df_final.to_excel(writer, sheet_name='merged_data', index=False)"
      ],
      "metadata": {
        "id": "SzBLmdagqMqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "ds = xr.open_dataset(\"./dataprep/C3S-LC-L4-LCCS-Map-300m-P1Y-2022-v2.1.1.nc\")\n",
        "\n",
        "lc = ds['lccs_class'].isel(time=0)\n",
        "\n",
        "lats = ds['lat'].values\n",
        "lons = ds['lon'].values\n",
        "\n",
        "points_df = pd.DataFrame({\n",
        "    'Latitude': [-18.28672791],\n",
        "    'Longitude': [143.4812469]\n",
        "})\n",
        "\n",
        "def nearest_index(array, value):\n",
        "    return (np.abs(array - value)).argmin()\n",
        "\n",
        "\n",
        "land_cover_values = []\n",
        "for idx, row in points_df.iterrows():\n",
        "    lat_idx = nearest_index(lats, row['Latitude'])\n",
        "    lon_idx = nearest_index(lons, row['Longitude'])\n",
        "\n",
        "    lc_value = lc.values[lat_idx, lon_idx]\n",
        "    land_cover_values.append(lc_value)\n",
        "\n",
        "points_df['Land_Cover_Code'] = land_cover_values\n",
        "print(points_df)"
      ],
      "metadata": {
        "id": "BqwABhDtR1E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "excel_path = \"./dataprep/species_test.xlsx\"\n",
        "df = pd.read_excel(excel_path,sheet_name='test_locs')\n",
        "df = df.rename(columns={0:'latitude', 1:'longitude'})\n",
        "print(list(df))"
      ],
      "metadata": {
        "id": "I_tIaTQy5R9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ADDING FEATURE LAND COVER TYPE - FINAL CODE USED (for both train and test data)\n",
        "import xarray as xr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "excel_path = \"./dataprep/species_test.xlsx\"\n",
        "df = pd.read_excel(excel_path,sheet_name='test_locs')\n",
        "df = df.rename(columns={0:'latitude', 1:'longitude'}) #Only for test dataset\n",
        "lat_col = 'latitude'\n",
        "lon_col = 'longitude'\n",
        "\n",
        "nc_path = \"./dataprep/C3S-LC-L4-LCCS-Map-300m-P1Y-2022-v2.1.1.nc\"\n",
        "ds = xr.open_dataset(nc_path)\n",
        "\n",
        "lc = ds['lccs_class'].isel(time=0)\n",
        "\n",
        "lats = ds['lat'].values\n",
        "lons = ds['lon'].values\n",
        "\n",
        "def nearest_index(array, value):\n",
        "    return (np.abs(array - value)).argmin()\n",
        "\n",
        "land_cover_map = {\n",
        "    0: {\"name\": \"No Data\", \"category\": \"Unknown\"},\n",
        "    10: {\"name\": \"Cropland, rainfed\", \"category\": \"Agriculture\"},\n",
        "    11: {\"name\": \"Herbaceous cover\", \"category\": \"Agriculture\"},\n",
        "    12: {\"name\": \"Tree or shrub cover\", \"category\": \"Agriculture\"},\n",
        "    20: {\"name\": \"Cropland, irrigated or post-flooding\", \"category\": \"Agriculture\"},\n",
        "    30: {\"name\": \"Mosaic cropland (>50%) / natural vegetation (<50%)\", \"category\": \"Mixed vegetation\"},\n",
        "    40: {\"name\": \"Mosaic natural vegetation (>50%) / cropland (<50%)\", \"category\": \"Mixed vegetation\"},\n",
        "    50: {\"name\": \"Tree cover, broadleaved, evergreen, closed to open (>15%)\", \"category\": \"Forest\"},\n",
        "    60: {\"name\": \"Tree cover, broadleaved, deciduous, closed to open (>15%)\", \"category\": \"Forest\"},\n",
        "    61: {\"name\": \"Tree cover, broadleaved, deciduous, closed to open (>40%)\", \"category\": \"Forest\"},\n",
        "    62: {\"name\": \"Tree cover, broadleaved, deciduous, open (15–40%)\", \"category\": \"Forest\"},\n",
        "    70: {\"name\": \"Tree cover, needleleaved, evergreen, closed to open (>15%)\", \"category\": \"Forest\"},\n",
        "    71: {\"name\": \"Tree cover, needleleaved, evergreen, closed to open (>40%)\", \"category\": \"Forest\"},\n",
        "    72: {\"name\": \"Tree cover, needleleaved, evergreen, open (15–40%)\", \"category\": \"Forest\"},\n",
        "    80: {\"name\": \"Tree cover, needleleaved, deciduous, closed to open (>15%)\", \"category\": \"Forest\"},\n",
        "    81: {\"name\": \"Tree cover, needleleaved, deciduous, closed to open (>40%)\", \"category\": \"Forest\"},\n",
        "    82: {\"name\": \"Tree cover, needleleaved, deciduous, open (15–40%)\", \"category\": \"Forest\"},\n",
        "    90: {\"name\": \"Tree cover, mixed leaf type (broadleaved + needleleaved)\", \"category\": \"Forest\"},\n",
        "    100: {\"name\": \"Mosaic tree and shrub (>50%) / herbaceous cover (<50%)\", \"category\": \"Mixed vegetation\"},\n",
        "    110: {\"name\": \"Mosaic herbaceous cover (>50%) / tree and shrub (<50%)\", \"category\": \"Mixed vegetation\"},\n",
        "    120: {\"name\": \"Shrubland\", \"category\": \"Shrubland\"},\n",
        "    121: {\"name\": \"Evergreen shrubland\", \"category\": \"Shrubland\"},\n",
        "    122: {\"name\": \"Deciduous shrubland\", \"category\": \"Shrubland\"},\n",
        "    130: {\"name\": \"Grassland\", \"category\": \"Grassland\"},\n",
        "    140: {\"name\": \"Lichens and mosses\", \"category\": \"Tundra\"},\n",
        "    150: {\"name\": \"Sparse vegetation (tree/shrub/herbaceous cover <15%)\", \"category\": \"Semi-arid\"},\n",
        "    151: {\"name\": \"Sparse tree (<15%)\", \"category\": \"Semi-arid\"},\n",
        "    152: {\"name\": \"Sparse shrub (<15%)\", \"category\": \"Semi-arid\"},\n",
        "    153: {\"name\": \"Sparse herbaceous cover (<15%)\", \"category\": \"Semi-arid\"},\n",
        "    160: {\"name\": \"Tree cover, flooded, fresh or brackish water\", \"category\": \"Wetlands\"},\n",
        "    170: {\"name\": \"Tree cover, flooded, saline water\", \"category\": \"Wetlands\"},\n",
        "    180: {\"name\": \"Shrub or herbaceous cover, flooded, fresh/saline/brackish water\", \"category\": \"Wetlands\"},\n",
        "    190: {\"name\": \"Urban areas\", \"category\": \"Urban\"},\n",
        "    200: {\"name\": \"Bare areas\", \"category\": \"Bare land\"},\n",
        "    201: {\"name\": \"Consolidated bare areas\", \"category\": \"Bare land\"},\n",
        "    202: {\"name\": \"Unconsolidated bare areas\", \"category\": \"Bare land\"},\n",
        "    210: {\"name\": \"Water bodies\", \"category\": \"Water\"},\n",
        "    220: {\"name\": \"Permanent snow & ice\", \"category\": \"Ice/Snow\"}\n",
        "}\n",
        "\n",
        "land_cover_types = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    lat = row[lat_col]\n",
        "    lon = row[lon_col]\n",
        "\n",
        "    lat_idx = nearest_index(lats, lat)\n",
        "    lon_idx = nearest_index(lons, lon)\n",
        "\n",
        "    lc_code = int(lc.values[lat_idx, lon_idx])\n",
        "\n",
        "    info = land_cover_map.get(lc_code, {\"name\": \"Unknown\", \"category\": \"Unknown\"})\n",
        "\n",
        "    land_cover_types.append(info[\"category\"])\n",
        "\n",
        "df[\"Land_Cover_Type\"] = land_cover_types\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
        "    df.to_excel(writer, sheet_name=\"test_locs\", index=False)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "zC9yND4TSgXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install earthengine-api"
      ],
      "metadata": {
        "id": "Wlw-B4pTnwP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install geopy"
      ],
      "metadata": {
        "id": "9QR9_ETAXxE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oceans = gpd.read_file(\"./dataprep/GOaS_v1_20211214/goas_v01.shp\")\n",
        "print(oceans.columns)"
      ],
      "metadata": {
        "id": "uJymtbYbRmkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fiona"
      ],
      "metadata": {
        "id": "T6qkpP8eFDQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fiona\n",
        "fiona.listlayers(\"./dataprep/gadm_410.gpkg\")"
      ],
      "metadata": {
        "id": "Vnujc71IE4tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gadm = gpd.read_file(\"./dataprep/gadm_410.gpkg\")\n",
        "print(gadm.columns)"
      ],
      "metadata": {
        "id": "ofrXin_GFK-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ADDING FEATURE REGION IN DATASET - FINAL PEICE OF CODE USED (for both train and test data)\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "\n",
        "excel_path = \"./dataprep/species_test.xlsx\"\n",
        "sheet_name = \"test_locs\"\n",
        "\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "geometry = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]\n",
        "gdf_points = gpd.GeoDataFrame(df, geometry=geometry, crs=\"EPSG:4326\")\n",
        "\n",
        "gadm = gpd.read_file(\"./dataprep/gadm_410.gpkg\")\n",
        "gadm = gadm[['NAME_0', 'NAME_1', 'geometry']]\n",
        "\n",
        "gdf_points = gdf_points.to_crs(gadm.crs)\n",
        "\n",
        "gdf_points = gpd.sjoin(\n",
        "    gdf_points,\n",
        "    gadm,\n",
        "    how=\"left\",\n",
        "    predicate=\"within\",\n",
        "    lsuffix='left',\n",
        "    rsuffix='right'\n",
        ")\n",
        "\n",
        "candidates = gdf_points[gdf_points['NAME_1'].isna()].copy()\n",
        "if 'index_right' in candidates.columns:\n",
        "    candidates.drop(columns=['index_right'], inplace=True)\n",
        "\n",
        "goas = gpd.read_file(\"./dataprep/GOaS_v1_20211214/goas_v01.shp\")\n",
        "marine_name_col = 'name'\n",
        "\n",
        "candidates = candidates.to_crs(goas.crs)\n",
        "\n",
        "marine_points = gpd.sjoin(\n",
        "    candidates,\n",
        "    goas[['geometry', marine_name_col]],\n",
        "    how=\"left\",\n",
        "    predicate=\"within\",\n",
        "    lsuffix='left',\n",
        "    rsuffix='right'\n",
        ")\n",
        "\n",
        "gdf_points['region'] = gdf_points['NAME_1']\n",
        "\n",
        "gdf_points.loc[gdf_points.index.isin(marine_points.index), 'region'] = marine_points[marine_name_col].values\n",
        "\n",
        "def polar_region(lat):\n",
        "    if lat < -60:\n",
        "        return \"Ice/Snow\"\n",
        "    elif lat > 75:\n",
        "        return \"Ice/Snow\"\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "mask_unknown = gdf_points['region'].isna() | (gdf_points['region']==\"\")\n",
        "gdf_points.loc[mask_unknown, 'region'] = gdf_points.loc[mask_unknown, 'latitude'].apply(polar_region)\n",
        "\n",
        "gdf_points['region'] = gdf_points['region'].fillna(\"Unknown\")\n",
        "\n",
        "output_cols = df.columns.tolist() + ['region']\n",
        "final_df = gdf_points[output_cols]\n",
        "\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
        "    final_df.to_excel(writer, sheet_name=sheet_name, index=False)\n"
      ],
      "metadata": {
        "id": "r0DN6zVyLh8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ADDING FEATURE - ANNUAL AVERAGE TEMPERATURE & PRECIPITATION - FINAL PEICE OF CODE USED (for both train and test data)\n",
        "import os\n",
        "import pandas as pd\n",
        "import rasterio\n",
        "from shapely.geometry import Point\n",
        "import numpy as np\n",
        "\n",
        "excel_path = \"./dataprep/species_test.xlsx\"\n",
        "sheet_name = \"test_locs\"\n",
        "\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "geometry = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]\n",
        "\n",
        "tmin_folder = \"./dataprep/wc2.1_cruts4.09_5m_tmin_2020-2024\"\n",
        "tmax_folder = \"./dataprep/wc2.1_cruts4.09_5m_tmax_2020-2024\"\n",
        "prec_folder = \"./dataprep/wc2.1_cruts4.09_5m_prec_2020-2024\"\n",
        "\n",
        "tmin_files = sorted([os.path.join(tmin_folder, f) for f in os.listdir(tmin_folder) if f.endswith(\".tif\")])\n",
        "tmax_files = sorted([os.path.join(tmax_folder, f) for f in os.listdir(tmax_folder) if f.endswith(\".tif\")])\n",
        "prec_files = sorted([os.path.join(prec_folder, f) for f in os.listdir(prec_folder) if f.endswith(\".tif\")])\n",
        "\n",
        "def extract_raster_values(raster_files, points):\n",
        "    values_all = []\n",
        "    for f in raster_files:\n",
        "        with rasterio.open(f) as src:\n",
        "            vals = []\n",
        "            for pt in points:\n",
        "                try:\n",
        "                    val = list(src.sample([(pt.x, pt.y)]))[0][0]\n",
        "                    if np.isnan(val):\n",
        "                        val = np.nan\n",
        "                except:\n",
        "                    val = np.nan\n",
        "                vals.append(val)\n",
        "            values_all.append(vals)\n",
        "    return list(map(list, zip(*values_all)))\n",
        "\n",
        "tmin_values = extract_raster_values(tmin_files, geometry)\n",
        "tmax_values = extract_raster_values(tmax_files, geometry)\n",
        "prec_values = extract_raster_values(prec_files, geometry)\n",
        "\n",
        "def group_by_year(files):\n",
        "    groups = {}\n",
        "    for i, f in enumerate(files):\n",
        "        year = os.path.basename(f).split(\"_\")[-1].split(\"-\")[0]\n",
        "        groups.setdefault(year, []).append(i)\n",
        "    return groups\n",
        "\n",
        "tmin_groups = group_by_year(tmin_files)\n",
        "tmax_groups = group_by_year(tmax_files)\n",
        "prec_groups = group_by_year(prec_files)\n",
        "\n",
        "for year in tmin_groups.keys():\n",
        "    tavg_year = []\n",
        "    prec_year = []\n",
        "\n",
        "    for point_idx in range(len(df)):\n",
        "        tmin_months = [tmin_values[point_idx][i] for i in tmin_groups[year]]\n",
        "        tmax_months = [tmax_values[point_idx][i] for i in tmax_groups[year]]\n",
        "        prec_months = [prec_values[point_idx][i] for i in prec_groups[year]]\n",
        "\n",
        "        tavg_months = [(tmin + tmax) / 2 if not np.isnan(tmin) and not np.isnan(tmax) else np.nan\n",
        "                       for tmin, tmax in zip(tmin_months, tmax_months)]\n",
        "\n",
        "        tavg_year.append(np.nanmean(tavg_months))\n",
        "        prec_year.append(np.nanmean(prec_months))\n",
        "\n",
        "    df[f'tavg_{year}_mean'] = tavg_year\n",
        "    df[f'prec_{year}_mean'] = prec_year\n",
        "\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)\n"
      ],
      "metadata": {
        "id": "CSYWEBhgkvbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ADDING FEATURE - ELEVATION - FINAL PEICE OF CODE USED (for both train and test data)\n",
        "import rasterio\n",
        "import pandas as pd\n",
        "from shapely.geometry import Point\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#excel_path = \"/Users/jayashreehariharan/Desktop/AML_Project/Species-2/species/Merged_train_data.xlsx\"\n",
        "#sheet_name = \"merged_data\"\n",
        "excel_path = \"./dataprep/species_test.xlsx\"\n",
        "sheet_name = \"test_locs\"\n",
        "\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "geometry = [Point(xy) for xy in zip(df['longitude'], df['latitude'])]\n",
        "\n",
        "elev_path = \"./dataprep/wc2.1_5m_elev.tif\"\n",
        "\n",
        "elevation_values = []\n",
        "with rasterio.open(elev_path) as src:\n",
        "    for pt in geometry:\n",
        "        try:\n",
        "            val = list(src.sample([(pt.x, pt.y)]))[0][0]\n",
        "            if np.isnan(val):\n",
        "                val = np.nan\n",
        "        except:\n",
        "            val = np.nan\n",
        "        elevation_values.append(val)\n",
        "\n",
        "df[\"elevation\"] = elevation_values\n",
        "\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ],
      "metadata": {
        "id": "rZYfdFkYrY_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "CAqE9iN1rH3k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcrvhmSQAOwX"
      },
      "outputs": [],
      "source": [
        "#Feature Engineering - adding climate trend features - Train Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "excel_path = \"./dataprep/Merged_train_data.xlsx\"\n",
        "sheet_name = \"merged_data\"\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "\n",
        "tavg_cols = ['tavg_2020_mean','tavg_2021_mean','tavg_2022_mean','tavg_2023_mean','tavg_2024_mean']\n",
        "prec_cols = ['prec_2020_mean','prec_2021_mean','prec_2022_mean','prec_2023_mean','prec_2024_mean']\n",
        "\n",
        "years = np.array([2020, 2021, 2022, 2023, 2024])\n",
        "\n",
        "tavg_values = df[tavg_cols].values\n",
        "\n",
        "tavg_trend = np.polyfit(years, tavg_values.T, 1)[0]\n",
        "\n",
        "def compute_slope(values, years):\n",
        "    x = years\n",
        "    x_mean = x.mean()\n",
        "    x_diff2 = np.sum((x - x_mean)**2)\n",
        "    slopes = np.sum((values - values.mean(axis=1, keepdims=True)) * (x - x_mean), axis=1) / x_diff2\n",
        "    return slopes\n",
        "\n",
        "df['tavg_trend'] = compute_slope(tavg_values, years)\n",
        "df['prec_trend'] = compute_slope(df[prec_cols].values, years)\n",
        "\n",
        "df['tavg_std'] = tavg_values.std(axis=1)\n",
        "df['prec_std'] = df[prec_cols].values.std(axis=1)\n",
        "\n",
        "df['tavg_max'] = tavg_values.max(axis=1)\n",
        "df['tavg_min'] = tavg_values.min(axis=1)\n",
        "df['tavg_range'] = df['tavg_max'] - df['tavg_min']\n",
        "\n",
        "df['prec_max'] = df[prec_cols].values.max(axis=1)\n",
        "df['prec_min'] = df[prec_cols].values.min(axis=1)\n",
        "df['prec_range'] = df['prec_max'] - df['prec_min']\n",
        "\n",
        "df['tavg_cv'] = df['tavg_std'] / df['tavg_mean'] if 'tavg_mean' in df.columns else df['tavg_std'] / tavg_values.mean(axis=1)\n",
        "df['prec_cv'] = df['prec_std'] / df['prec_mean'] if 'prec_mean' in df.columns else df['prec_std'] / df[prec_cols].values.mean(axis=1)\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU9jxwKjBwyk"
      },
      "outputs": [],
      "source": [
        "#Feature Engineering - adding climate trend features - Test Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "excel_path = \"./dataprep/species_test.xlsx\"\n",
        "sheet_name = \"test_locs\"\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "\n",
        "tavg_cols = ['tavg_2020_mean','tavg_2021_mean','tavg_2022_mean','tavg_2023_mean','tavg_2024_mean']\n",
        "prec_cols = ['prec_2020_mean','prec_2021_mean','prec_2022_mean','prec_2023_mean','prec_2024_mean']\n",
        "\n",
        "years = np.array([2020, 2021, 2022, 2023, 2024])\n",
        "\n",
        "tavg_values = df[tavg_cols].values\n",
        "\n",
        "tavg_trend = np.polyfit(years, tavg_values.T, 1)[0]\n",
        "\n",
        "def compute_slope(values, years):\n",
        "    x = years\n",
        "    x_mean = x.mean()\n",
        "    x_diff2 = np.sum((x - x_mean)**2)\n",
        "    slopes = np.sum((values - values.mean(axis=1, keepdims=True)) * (x - x_mean), axis=1) / x_diff2\n",
        "    return slopes\n",
        "\n",
        "df['tavg_trend'] = compute_slope(tavg_values, years)\n",
        "df['prec_trend'] = compute_slope(df[prec_cols].values, years)\n",
        "\n",
        "df['tavg_std'] = tavg_values.std(axis=1)\n",
        "df['prec_std'] = df[prec_cols].values.std(axis=1)\n",
        "\n",
        "df['tavg_max'] = tavg_values.max(axis=1)\n",
        "df['tavg_min'] = tavg_values.min(axis=1)\n",
        "df['tavg_range'] = df['tavg_max'] - df['tavg_min']\n",
        "\n",
        "df['prec_max'] = df[prec_cols].values.max(axis=1)\n",
        "df['prec_min'] = df[prec_cols].values.min(axis=1)\n",
        "df['prec_range'] = df['prec_max'] - df['prec_min']\n",
        "\n",
        "df['tavg_cv'] = df['tavg_std'] / df['tavg_mean'] if 'tavg_mean' in df.columns else df['tavg_std'] / tavg_values.mean(axis=1)\n",
        "df['prec_cv'] = df['prec_std'] / df['prec_mean'] if 'prec_mean' in df.columns else df['prec_std'] / df[prec_cols].values.mean(axis=1)\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Engineering - encoding spatial continuity - Train Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import linregress\n",
        "\n",
        "excel_path = \"./dataprep/Merged_train_data.xlsx\"\n",
        "sheet_name = \"merged_data\"\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "\n",
        "df['lat_rad'] = np.radians(df['latitude'])\n",
        "df['lon_rad'] = np.radians(df['longitude'])\n",
        "\n",
        "df['lat_sin'] = np.sin(df['lat_rad'])\n",
        "df['lat_cos'] = np.cos(df['lat_rad'])\n",
        "df['lon_sin'] = np.sin(df['lon_rad'])\n",
        "df['lon_cos'] = np.cos(df['lon_rad'])\n",
        "\n",
        "df.drop(['lat_rad','lon_rad'], axis=1, inplace=True)\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ],
      "metadata": {
        "id": "9PkYoG0MFIVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Engineering - encoding spatial continuity - Test Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import linregress\n",
        "\n",
        "excel_path = \"./dataprep/species_test.xlsx\"\n",
        "sheet_name = \"test_locs\"\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "\n",
        "df['lat_rad'] = np.radians(df['latitude'])\n",
        "df['lon_rad'] = np.radians(df['longitude'])\n",
        "\n",
        "df['lat_sin'] = np.sin(df['lat_rad'])\n",
        "df['lat_cos'] = np.cos(df['lat_rad'])\n",
        "df['lon_sin'] = np.sin(df['lon_rad'])\n",
        "df['lon_cos'] = np.cos(df['lon_rad'])\n",
        "\n",
        "df.drop(['lat_rad','lon_rad'], axis=1, inplace=True)\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ],
      "metadata": {
        "id": "31Wt6c5fFmJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding all species taxon_id's found at a certain latitude and longitude\n",
        "import pandas as pd\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "\n",
        "file_path = \"./dataprep/species_test.xlsx\"\n",
        "output_file = \"./dataprep/species_test_with_species.xlsx\"\n",
        "\n",
        "sheet_locs = 'test_locs'\n",
        "sheet_indices = 'test_pos_inds'\n",
        "sheet_taxon_ids = 'taxon_ids'\n",
        "\n",
        "df_locs = pd.read_excel(file_path, sheet_name=sheet_locs)\n",
        "df_indices = pd.read_excel(file_path, sheet_name=sheet_indices)\n",
        "df_species_ids = pd.read_excel(file_path, sheet_name=sheet_taxon_ids)\n",
        "\n",
        "def fix_list_string(s):\n",
        "    s = str(s).strip()\n",
        "    if not s.startswith('['):\n",
        "        s = '[' + s\n",
        "    if s.endswith(','):\n",
        "        s = s[:-1] + ']'\n",
        "    elif not s.endswith(']'):\n",
        "        s = s + ']'\n",
        "    return s\n",
        "\n",
        "indices_lists = []\n",
        "for i, row in tqdm(df_indices.iterrows(), total=df_indices.shape[0], desc=\"Processing indices\"):\n",
        "    cell = row[0]\n",
        "    fixed = fix_list_string(cell)\n",
        "    try:\n",
        "        indices_list = ast.literal_eval(fixed)\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing row {i}: {e}\")\n",
        "        indices_list = []\n",
        "    indices_lists.append(indices_list)\n",
        "\n",
        "species_idx_pairs = [\n",
        "    (sp_id, [x-1 for x in idx_list if pd.notna(x)])\n",
        "    for sp_id, idx_list in zip(df_species_ids.iloc[:,0], indices_lists)\n",
        "]\n",
        "\n",
        "df_locs['species'] = [[] for _ in range(len(df_locs))]\n",
        "\n",
        "for sp_id, idx_list in tqdm(species_idx_pairs, desc=\"Mapping species to locations\"):\n",
        "    for idx in idx_list:\n",
        "        if 0 <= idx < len(df_locs):\n",
        "            df_locs.at[idx, 'species'].append(sp_id)\n",
        "\n",
        "with pd.ExcelWriter(file_path, engine=\"openpyxl\") as writer:\n",
        "    df_locs.to_excel(writer, sheet_name=sheet_locs, index=False)"
      ],
      "metadata": {
        "id": "B6YSmIZiV8xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing all data in test dataset based on latitudes and longitudes combo not having any species\n",
        "import pandas as pd\n",
        "excel_path = \"./dataprep/test_data_locs_with_species_only.xlsx\"\n",
        "sheet_name = \"test_locs\"\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "\n",
        "df = df[df.species != '[]']\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
        "    df.to_excel(writer, sheet_name=\"clean_test\", index=False)"
      ],
      "metadata": {
        "id": "wTOkNM18ZOYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Spatial Extrapolation"
      ],
      "metadata": {
        "id": "y3BtuGIRre9k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLlPHYcQiL9A"
      },
      "outputs": [],
      "source": [
        "#SPATIAL EXTRAPOLATION FOR TEMPERATURE AND PRECIPITATION - TRAIN DATA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "excel_path = \"./dataprep/Merged_train_data.xlsx\"\n",
        "sheet_name = \"merged_data\"\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "\n",
        "cols_to_fill = [\n",
        "    'tavg_2020_mean','prec_2020_mean',\n",
        "    'tavg_2021_mean','prec_2021_mean',\n",
        "    'tavg_2022_mean','prec_2022_mean',\n",
        "    'tavg_2023_mean','prec_2023_mean',\n",
        "    'tavg_2024_mean','prec_2024_mean'\n",
        "]\n",
        "\n",
        "valid = df.dropna(subset=cols_to_fill, how='all').reset_index(drop=True)\n",
        "missing = df[df[cols_to_fill].isna().any(axis=1)].reset_index()\n",
        "\n",
        "def haversine_vectorized(lat1, lon1, lat2, lon2):\n",
        "    R = 6371\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1[:, None]\n",
        "    dlon = lon2 - lon1[:, None]\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1)[:, None] * np.cos(lat2) * np.sin(dlon/2)**2\n",
        "    a = np.clip(a, 0, 1)\n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
        "    return R * c\n",
        "\n",
        "dist_matrix = haversine_vectorized(\n",
        "    missing['latitude'].values,\n",
        "    missing['longitude'].values,\n",
        "    valid['latitude'].values,\n",
        "    valid['longitude'].values\n",
        ")\n",
        "\n",
        "nearest_indices = np.argmin(dist_matrix, axis=1)\n",
        "\n",
        "for idx_missing, idx_valid in zip(missing['index'], nearest_indices):\n",
        "    for col in cols_to_fill:\n",
        "        if pd.isna(df.at[idx_missing, col]):\n",
        "            df.at[idx_missing, col] = valid.at[idx_valid, col]\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SPATIAL EXTRAPOLATION FOR TEMPERATURE AND PRECIPITATION - TEST DATA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.spatial import cKDTree\n",
        "\n",
        "excel_path = \"./dataprep/species_test.xlsx\"\n",
        "sheet_name = \"test_locs\"\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "\n",
        "cols_to_fill = [\n",
        "    'tavg_2020_mean','prec_2020_mean',\n",
        "    'tavg_2021_mean','prec_2021_mean',\n",
        "    'tavg_2022_mean','prec_2022_mean',\n",
        "    'tavg_2023_mean','prec_2023_mean',\n",
        "    'tavg_2024_mean','prec_2024_mean'\n",
        "]\n",
        "\n",
        "valid = df.dropna(subset=cols_to_fill, how='all').reset_index(drop=True)\n",
        "missing = df[df[cols_to_fill].isna().any(axis=1)].reset_index()\n",
        "\n",
        "def latlon_to_xyz(lat, lon):\n",
        "    lat_rad = np.radians(lat)\n",
        "    lon_rad = np.radians(lon)\n",
        "    x = np.cos(lat_rad) * np.cos(lon_rad)\n",
        "    y = np.cos(lat_rad) * np.sin(lon_rad)\n",
        "    z = np.sin(lat_rad)\n",
        "    return np.column_stack((x, y, z))\n",
        "\n",
        "valid_xyz = latlon_to_xyz(valid['latitude'].values, valid['longitude'].values)\n",
        "missing_xyz = latlon_to_xyz(missing['latitude'].values, missing['longitude'].values)\n",
        "\n",
        "tree = cKDTree(valid_xyz)\n",
        "\n",
        "_, nearest_idx = tree.query(missing_xyz, k=1)\n",
        "\n",
        "for idx_missing, idx_valid in zip(missing['index'], nearest_idx):\n",
        "    for col in cols_to_fill:\n",
        "        if pd.isna(df.at[idx_missing, col]):\n",
        "            df.at[idx_missing, col] = valid.at[idx_valid, col]\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "print(\"Missing values filled\")"
      ],
      "metadata": {
        "id": "QQbsa2Gu8OKS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}