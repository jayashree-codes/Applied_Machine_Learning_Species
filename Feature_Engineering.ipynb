{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTwBvmUX20AjbuPgdwp3/3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jayashree-codes/Applied_Machine_Learning_Species/blob/main/Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcrvhmSQAOwX"
      },
      "outputs": [],
      "source": [
        "#Feature Engineering - adding climate trend features - Train Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "excel_path = \"/Users/jayashreehariharan/Desktop/AML_Project/Species-2/species/Merged_train_data.xlsx\"\n",
        "sheet_name = \"merged_data\"\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "\n",
        "tavg_cols = ['tavg_2020_mean','tavg_2021_mean','tavg_2022_mean','tavg_2023_mean','tavg_2024_mean']\n",
        "prec_cols = ['prec_2020_mean','prec_2021_mean','prec_2022_mean','prec_2023_mean','prec_2024_mean']\n",
        "\n",
        "years = np.array([2020, 2021, 2022, 2023, 2024])\n",
        "\n",
        "tavg_values = df[tavg_cols].values\n",
        "\n",
        "tavg_trend = np.polyfit(years, tavg_values.T, 1)[0]\n",
        "\n",
        "def compute_slope(values, years):\n",
        "    x = years\n",
        "    x_mean = x.mean()\n",
        "    x_diff2 = np.sum((x - x_mean)**2)\n",
        "    slopes = np.sum((values - values.mean(axis=1, keepdims=True)) * (x - x_mean), axis=1) / x_diff2\n",
        "    return slopes\n",
        "\n",
        "df['tavg_trend'] = compute_slope(tavg_values, years)\n",
        "df['prec_trend'] = compute_slope(df[prec_cols].values, years)\n",
        "\n",
        "df['tavg_std'] = tavg_values.std(axis=1)\n",
        "df['prec_std'] = df[prec_cols].values.std(axis=1)\n",
        "\n",
        "df['tavg_max'] = tavg_values.max(axis=1)\n",
        "df['tavg_min'] = tavg_values.min(axis=1)\n",
        "df['tavg_range'] = df['tavg_max'] - df['tavg_min']\n",
        "\n",
        "df['prec_max'] = df[prec_cols].values.max(axis=1)\n",
        "df['prec_min'] = df[prec_cols].values.min(axis=1)\n",
        "df['prec_range'] = df['prec_max'] - df['prec_min']\n",
        "\n",
        "df['tavg_cv'] = df['tavg_std'] / df['tavg_mean'] if 'tavg_mean' in df.columns else df['tavg_std'] / tavg_values.mean(axis=1)\n",
        "df['prec_cv'] = df['prec_std'] / df['prec_mean'] if 'prec_mean' in df.columns else df['prec_std'] / df[prec_cols].values.mean(axis=1)\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sSHBcKHpBt6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU9jxwKjBwyk"
      },
      "outputs": [],
      "source": [
        "#Feature Engineering - adding climate trend features - Test Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "excel_path = \"/Users/jayashreehariharan/Desktop/AML_Project/Species-2/species/species_test.xlsx\"\n",
        "sheet_name = \"test_locs\"\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "\n",
        "tavg_cols = ['tavg_2020_mean','tavg_2021_mean','tavg_2022_mean','tavg_2023_mean','tavg_2024_mean']\n",
        "prec_cols = ['prec_2020_mean','prec_2021_mean','prec_2022_mean','prec_2023_mean','prec_2024_mean']\n",
        "\n",
        "years = np.array([2020, 2021, 2022, 2023, 2024])\n",
        "\n",
        "tavg_values = df[tavg_cols].values\n",
        "\n",
        "tavg_trend = np.polyfit(years, tavg_values.T, 1)[0]\n",
        "\n",
        "def compute_slope(values, years):\n",
        "    x = years\n",
        "    x_mean = x.mean()\n",
        "    x_diff2 = np.sum((x - x_mean)**2)\n",
        "    slopes = np.sum((values - values.mean(axis=1, keepdims=True)) * (x - x_mean), axis=1) / x_diff2\n",
        "    return slopes\n",
        "\n",
        "df['tavg_trend'] = compute_slope(tavg_values, years)\n",
        "df['prec_trend'] = compute_slope(df[prec_cols].values, years)\n",
        "\n",
        "df['tavg_std'] = tavg_values.std(axis=1)\n",
        "df['prec_std'] = df[prec_cols].values.std(axis=1)\n",
        "\n",
        "df['tavg_max'] = tavg_values.max(axis=1)\n",
        "df['tavg_min'] = tavg_values.min(axis=1)\n",
        "df['tavg_range'] = df['tavg_max'] - df['tavg_min']\n",
        "\n",
        "df['prec_max'] = df[prec_cols].values.max(axis=1)\n",
        "df['prec_min'] = df[prec_cols].values.min(axis=1)\n",
        "df['prec_range'] = df['prec_max'] - df['prec_min']\n",
        "\n",
        "df['tavg_cv'] = df['tavg_std'] / df['tavg_mean'] if 'tavg_mean' in df.columns else df['tavg_std'] / tavg_values.mean(axis=1)\n",
        "df['prec_cv'] = df['prec_std'] / df['prec_mean'] if 'prec_mean' in df.columns else df['prec_std'] / df[prec_cols].values.mean(axis=1)\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Engineering - encoding spatial continuity - Train Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import linregress\n",
        "\n",
        "excel_path = \"/Users/jayashreehariharan/Desktop/AML_Project/Species-2/species/Merged_train_data.xlsx\"\n",
        "sheet_name = \"merged_data\"\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "\n",
        "df['lat_rad'] = np.radians(df['latitude'])\n",
        "df['lon_rad'] = np.radians(df['longitude'])\n",
        "\n",
        "df['lat_sin'] = np.sin(df['lat_rad'])\n",
        "df['lat_cos'] = np.cos(df['lat_rad'])\n",
        "df['lon_sin'] = np.sin(df['lon_rad'])\n",
        "df['lon_cos'] = np.cos(df['lon_rad'])\n",
        "\n",
        "df.drop(['lat_rad','lon_rad'], axis=1, inplace=True)\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ],
      "metadata": {
        "id": "9PkYoG0MFIVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Engineering - encoding spatial continuity - Test Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import linregress\n",
        "\n",
        "excel_path = \"/Users/jayashreehariharan/Desktop/AML_Project/Species-2/species/species_test.xlsx\"\n",
        "sheet_name = \"test_locs\"\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "\n",
        "df['lat_rad'] = np.radians(df['latitude'])\n",
        "df['lon_rad'] = np.radians(df['longitude'])\n",
        "\n",
        "df['lat_sin'] = np.sin(df['lat_rad'])\n",
        "df['lat_cos'] = np.cos(df['lat_rad'])\n",
        "df['lon_sin'] = np.sin(df['lon_rad'])\n",
        "df['lon_cos'] = np.cos(df['lon_rad'])\n",
        "\n",
        "df.drop(['lat_rad','lon_rad'], axis=1, inplace=True)\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
        "    df.to_excel(writer, sheet_name=sheet_name, index=False)"
      ],
      "metadata": {
        "id": "31Wt6c5fFmJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e022e9b-08a6-4f09-f039-81c5852c02cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding all species taxon_id's found at a certain latitude and longitude\n",
        "import pandas as pd\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "\n",
        "file_path = \"/Users/jayashreehariharan/Desktop/AML_Project/Species-2/species/species_test.xlsx\"\n",
        "output_file = \"/Users/jayashreehariharan/Desktop/AML_Project/Species-2/species/species_test_with_species.xlsx\"\n",
        "\n",
        "sheet_locs = 'test_locs'\n",
        "sheet_indices = 'test_pos_inds'\n",
        "sheet_taxon_ids = 'taxon_ids'\n",
        "\n",
        "df_locs = pd.read_excel(file_path, sheet_name=sheet_locs)\n",
        "df_indices = pd.read_excel(file_path, sheet_name=sheet_indices)\n",
        "df_species_ids = pd.read_excel(file_path, sheet_name=sheet_taxon_ids)\n",
        "\n",
        "def fix_list_string(s):\n",
        "    s = str(s).strip()\n",
        "    if not s.startswith('['):\n",
        "        s = '[' + s\n",
        "    if s.endswith(','):\n",
        "        s = s[:-1] + ']'\n",
        "    elif not s.endswith(']'):\n",
        "        s = s + ']'\n",
        "    return s\n",
        "\n",
        "indices_lists = []\n",
        "for i, row in tqdm(df_indices.iterrows(), total=df_indices.shape[0], desc=\"Processing indices\"):\n",
        "    cell = row[0]\n",
        "    fixed = fix_list_string(cell)\n",
        "    try:\n",
        "        indices_list = ast.literal_eval(fixed)\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing row {i}: {e}\")\n",
        "        indices_list = []\n",
        "    indices_lists.append(indices_list)\n",
        "\n",
        "species_idx_pairs = [\n",
        "    (sp_id, [x-1 for x in idx_list if pd.notna(x)])\n",
        "    for sp_id, idx_list in zip(df_species_ids.iloc[:,0], indices_lists)\n",
        "]\n",
        "\n",
        "df_locs['species'] = [[] for _ in range(len(df_locs))]\n",
        "\n",
        "for sp_id, idx_list in tqdm(species_idx_pairs, desc=\"Mapping species to locations\"):\n",
        "    for idx in idx_list:\n",
        "        if 0 <= idx < len(df_locs):\n",
        "            df_locs.at[idx, 'species'].append(sp_id)\n",
        "\n",
        "with pd.ExcelWriter(file_path, engine=\"openpyxl\") as writer:\n",
        "    df_locs.to_excel(writer, sheet_name=sheet_locs, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6YSmIZiV8xX",
        "outputId": "76ffdefa-312b-4a23-fd8d-1e2915c14d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing indices:   0%|                                                                                                                                                               | 0/500 [00:00<?, ?it/s]/var/folders/3c/mlps6zvx11l75_fk761ppwlr0000gn/T/ipykernel_1398/1062631743.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  cell = row[0]\n",
            "Processing indices: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 709.64it/s]\n",
            "Mapping species to locations: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:01<00:00, 476.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done! 'species' column added to Sheet1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing all data in test dataset based on latitudes and longitudes combo not having any species\n",
        "import pandas as pd\n",
        "excel_path = \"/Users/jayashreehariharan/Desktop/AML_Project/Species-2/species/test_data_locs_with_species_only.xlsx\"\n",
        "sheet_name = \"test_locs\"\n",
        "df = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
        "\n",
        "df = df[df.species != '[]']\n",
        "\n",
        "with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
        "    df.to_excel(writer, sheet_name=\"clean_test\", index=False)"
      ],
      "metadata": {
        "id": "wTOkNM18ZOYJ"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}